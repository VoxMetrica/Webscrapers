{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSE Price and Volume Selenium Scraper\n",
    "This programme scrapes prices and volumes from the London Stock Exchange Website by iterating through\n",
    "the technical analysis page of various stocks and grabbing data from the charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from seleniumwire import webdriver\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "import scipy.interpolate as si\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "chrome_path = \"C:/Users/Graziano/Desktop/Python Files/Webdrivers/chromedriver.exe\"\n",
    "fire_path = \"C:/Users/Graziano/Desktop/Python Files/Webdrivers/geckodriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "today = f'{now.year}-{now.month}-{now.day}'\n",
    "year, month, day = 5,0,0\n",
    "start = f'{now.year - year}-{now.month - month}-{now.day - day}'\n",
    "end_period = int(time.mktime(time.strptime(today, '%Y-%m-%d')))\n",
    "start_period = int(time.mktime(time.strptime(start, '%Y-%m-%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url is the url that, combined with the four way key, gives the right url.\n",
    "base_url = 'https://www.londonstockexchange.com/exchange/prices-and-markets/stocks/exchange-insight/technical-analysis.html?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I do not set the options to run headlessly because it seems that I have to actually see the browsers\n",
    "# render the charts in order to capture the data.\n",
    "coptions = webdriver.ChromeOptions()\n",
    "coptions.add_argument(\"--start-maximized\")\n",
    "foptions = webdriver.FirefoxOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tickerfo is the dataframe with tickers and four way keys in the fundamentals tab link\n",
    "tickerfo = pd.read_csv(r'C:\\Users\\Graziano\\Desktop\\Trading\\IndexScraper\\ftse\\ftse350_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I extract the tickers and four way keys for those keys that aren't nans\n",
    "tickfo = tickerfo[~tickerfo.fund_link.isna()]\n",
    "keys = tickfo.fund_link.apply(lambda x: str(x).split('?')[-1])\n",
    "tickers = tickfo.tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the keys I generate a list of appropriate urls\n",
    "urls = [base_url + key for key in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I set the driver's scope and the number of tries and waits for the various functions.\n",
    "scopes = ['.*(G|g)et(P|p)rices(W|w)ith(V|v)olume']\n",
    "driver_tries, driver_wait = 20, 10\n",
    "url_tries, url_wait = 5, 10\n",
    "click_tries, click_wait = 5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create an array of ones and zeros indicating whether the chrome or firefox webdriver will be in\n",
    "# operation. I then turn that array into an array of ones, zeros, and minus ones, with the ones and minus\n",
    "# ones indicating that a new driver will be initiated after closing the old one, and zeros indicating\n",
    "# that the already existing driver will continue. This array will be zipped with the urls to control the\n",
    "# execution of the programme\n",
    "current = 0\n",
    "stringFlow = ''\n",
    "flow = []\n",
    "for itm in range(len(urls)-1):\n",
    "    if itm == 0:\n",
    "        flow.append(0)\n",
    "        stringFlow = stringFlow + '0'\n",
    "    else:\n",
    "        if np.random.uniform() < len(stringFlow.split('1')[-1])*0.04:\n",
    "            if current >= 0:\n",
    "                current = -1\n",
    "                flow.append(current)\n",
    "                stringFlow = stringFlow + str(current)\n",
    "            else:\n",
    "                current = 1\n",
    "                flow.append(current)\n",
    "                stringFlow = stringFlow + str(current)\n",
    "        else:\n",
    "            flow.append(0)\n",
    "            stringFlow = stringFlow + '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_changer(random):\n",
    "    '''This just changes -1 to 1 and vice versa'''\n",
    "    if random == 1:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_webdriver_start(comptrol, scopes=scopes, chrome_path=chrome_path, \n",
    "                           fire_path=fire_path, chrome_options=coptions, fire_options=foptions):\n",
    "    '''\n",
    "    This function randomly returns a new chrome or firefox seleniumwire webdriver\n",
    "    '''\n",
    "\n",
    "    if comptrol == 1:\n",
    "        try:\n",
    "            driver = webdriver.Chrome(executable_path=chrome_path,\n",
    "                                 options=coptions)\n",
    "        except:\n",
    "            #fp = webdriver.FirefoxProfile(r'C:\\Users\\Graziano\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\t3cpv2qe.selenium')\n",
    "            driver = webdriver.Firefox(executable_path=fire_path, \n",
    "                                       options=foptions)\n",
    "    else:\n",
    "        try:\n",
    "            #fp = webdriver.FirefoxProfile(r'C:\\Users\\Graziano\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\t3cpv2qe.selenium')\n",
    "            driver = webdriver.Firefox(executable_path=fire_path, \n",
    "                                       options=foptions)\n",
    "        except:\n",
    "            driver = webdriver.Chrome(executable_path=chrome_path,\n",
    "                                 options=coptions)\n",
    "\n",
    "    driver.scopes = scopes\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_driver(comptrol=1, tries=driver_tries, wait=driver_wait):\n",
    "    '''\n",
    "    This function uses the start_driver function to try to open a webdriver driver_tries times and waits\n",
    "    driver_wait seconds between tries.\n",
    "    '''\n",
    "    gate = 0\n",
    "    while gate < tries:\n",
    "        try:\n",
    "            driver = random_webdriver_start(comptrol)\n",
    "            gate = tries\n",
    "            return driver\n",
    "        except:\n",
    "            print(f'had to try again with the browser. Comptrol:: {comptrol}')\n",
    "            gate += 1\n",
    "            if gate == tries:\n",
    "                print('Could not start the driver','\\n'+'---------------------------------------------')\n",
    "                exit()\n",
    "            else:\n",
    "                time.sleep(driver_wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_url(driver,url,comptrol,url_tries=url_tries,url_wait=url_wait):\n",
    "    '''\n",
    "    try_url tries to get a url. If it fails, it tries again with a different browser. It tries url_tries\n",
    "    times and waits for url_wait seconds between tries. It also globally modifies the boolean 'skip' if\n",
    "    it fails to get the url.\n",
    "    '''\n",
    "    gate = 0\n",
    "    global skip\n",
    "    while gate < url_tries:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            gate = url_tries\n",
    "            skip = False\n",
    "        except:\n",
    "            gate += 1\n",
    "            # If I reach the last try and the try block has failed to execute, then I print an error\n",
    "            # message and set the skip parameter to True.\n",
    "            if gate == url_tries:\n",
    "                print(f'Could not get {url}')\n",
    "                skip = True\n",
    "            # for any other tries, I start a new browser by changing comptrol with random_changer and\n",
    "            # employing start_driver.\n",
    "            else:\n",
    "                driver.quit()\n",
    "                time.sleep(url_wait)\n",
    "                comptrol = random_changer(comptrol)\n",
    "                driver = start_driver(comptrol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clickety_click(driver,url,pre,click_tries=click_tries,click_wait=click_wait):\n",
    "    '''\n",
    "    This function moves to the 'add to portfolio' icon on the page and then mvoes left to get to the five\n",
    "    year button and clicks. If there aren't two more requests relative to pre, then it tries again, and\n",
    "    it tries again anyway if there is an error. It tries up to click_tries times and waits click_wait \n",
    "    seconds.\n",
    "    '''\n",
    "    # I use a while loop to make sure that the one year request has come through. This should hopefully\n",
    "    # mean that the five year button has loaded. Making sure this request has come through should also\n",
    "    # ensure that the rest of the code, which assumes two requests will come through, should work.\n",
    "    gate = 0\n",
    "    while len(driver.requests) - pre < 1 and gate < click_tries:\n",
    "        time.sleep(click_wait)\n",
    "        gate += 1\n",
    "    # Once I have waited, I assign the new number of requests to pre_click, so I can detect if the\n",
    "    # clicking has worked.\n",
    "    pre_click = len(driver.requests)\n",
    "    \n",
    "    gate = 0\n",
    "    while gate < click_tries:\n",
    "        try:\n",
    "            # portImg is a WebDriverWait that locates the portfolio icon using its xpath\n",
    "            portImg = WebDriverWait(driver, 30).until(ec.visibility_of_element_located((\n",
    "            By.XPATH, '//img[@alt=\"Add to Portfolio\"]')))\n",
    "            ActionChains(driver).move_to_element(portImg).move_by_offset(-100,0).click().perform()\n",
    "            # I need to sleep in order to let the full request load\n",
    "            time.sleep(5)\n",
    "            # if the number of new requests is 1, then that means that the clicking has been successful.\n",
    "            if len(driver.requests) - pre_click > 0:\n",
    "                gate = click_tries\n",
    "            else:\n",
    "                gate += 1\n",
    "        except:\n",
    "            gate += 1\n",
    "            # If I am on the last try then I print an error message.\n",
    "            if gate == click_tries:\n",
    "                print(f'could not clickety click {url}')\n",
    "            else:\n",
    "                time.sleep(click_wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(driver, pre, stonk, max_tries = 20, wait = 0.2):\n",
    "    '''\n",
    "    This function returns a list containng either nothing, or a pd dataframe with data from one of the\n",
    "    lse graphs.\n",
    "    '''\n",
    "    tries = 0\n",
    "    skip = False\n",
    "    # I use a while loop to check max_tries times for the appearence of two extra requests, though this\n",
    "    # condition is probably already met because I wait for two extra requests in clickety_click.\n",
    "    while len(driver.requests) - pre < 2 and tries < max_tries:\n",
    "        time.sleep(wait)\n",
    "        tries += 1\n",
    "    # I set the number of new requests as the 'new' variable in order to determine whether and which\n",
    "    # data to get.\n",
    "    new = len(driver.requests) - pre\n",
    "    \n",
    "    # If there are no new requests, then I return an empty list that concatenates with lse to get lse.\n",
    "    # This is because I have no new requests, so no new data.\n",
    "    if new == 0:\n",
    "        return []\n",
    "    # Otherwise, I wait until the last response is not None or until I have waited max_tries times.\n",
    "    else:\n",
    "        while driver.last_request.response is None and tries < max_tries:\n",
    "            time.sleep(wait)\n",
    "            tries += 1\n",
    "        # If the last response is indeed not None, then I capture the json data from the response and\n",
    "        # put it into a dataframe that I return in a list so as to be able to concatenate it. Note that\n",
    "        # this could be just the 1 year request as well as the five year request.\n",
    "        if driver.last_request.response is not None:\n",
    "            jsn = driver.last_request.response.body\n",
    "            data = json.loads(jsn)\n",
    "            df = pd.DataFrame(data['d'], columns = ['date','close','open','high','low','close_again',\n",
    "                                                    'volume'])\n",
    "            return [pd.concat([df.set_index('date')], keys=[stonk], axis=1)]\n",
    "        # Otherwise, if there is more than one request, then I check to see if the next to last request\n",
    "        # (which will either be a five year or one year request) has a response and capture that instead.\n",
    "        else:\n",
    "            if new > 1 and driver.requests[-2].response is not None:\n",
    "                jsn = driver.requests[-2].response.body\n",
    "                data = json.loads(jsn)\n",
    "                df = pd.DataFrame(data['d'], columns = ['date','close','open','high','low','close_again',\n",
    "                                                        'volume'])\n",
    "                return [pd.concat([df.set_index('date')], keys=[stonk], axis=1)]\n",
    "            # However, if the new number of requests is one, then we already saw that the last request\n",
    "            # had a None response, so there is no point in trying to capture data and I return []\n",
    "            else:\n",
    "                return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------- MAIN PROGRAMME ---------------------------------------- #\n",
    "# The main programme starts by going to the first url and gets its data and then deals with the rest\n",
    "# of the urls through a for loop. It starts by creating an empty dataframe called 'lse' and setting\n",
    "# comptrol to 1.\n",
    "lse = pd.DataFrame()\n",
    "comptrol = 1\n",
    "# I start with a Chrome webdriver using comptrol.\n",
    "driver = start_driver(comptrol)\n",
    "# skip is assigned to False, and will be changed in try_url if I fail to get the url\n",
    "skip = False\n",
    "# I establish 'pre' which tells me how many requests have been made before any url getting or clicking\n",
    "# takes place.\n",
    "pre = len(driver.requests)\n",
    "# I get the first url.\n",
    "try_url(driver,urls[0],comptrol)\n",
    "\n",
    "# if I couldn't get the url, then skip will have become true, so I skip the rest.\n",
    "if skip:\n",
    "    pass\n",
    "# Otherwise, I proceed with the programme\n",
    "else:\n",
    "    # I check that I have not hit a 'page not found' page by checking the h1 tag, and skip the rest if\n",
    "    # I have hit the page.\n",
    "    if driver.find_element_by_tag_name('h1').text.lower() == 'page not found':\n",
    "        pass\n",
    "    # Otherwise, everything is fine and I clickety_click and then get the data\n",
    "    else:\n",
    "        clickety_click(driver,urls[0],pre)\n",
    "\n",
    "        lse = pd.concat([lse] + get_data(driver,pre,tickers[0]), axis = 1)\n",
    "\n",
    "# I begin a for loop based on a zip of previously defined lists.\n",
    "for url, comptrol, stonk in list(zip(urls[1:], flow, tickers[1:]))[:5]:\n",
    "    # if comptrol is zero, then that means that I am continuing with the existing driver\n",
    "    if comptrol == 0:\n",
    "        # I set skip to False just in case it was changed to True when getting the previous url\n",
    "        skip = False\n",
    "        # I define pre, which in this case is especially important because the number of requests will not\n",
    "        # be zero\n",
    "        pre = len(driver.requests)\n",
    "        # The rest of the programme proceeds just as in the first instance.\n",
    "        try_url(driver,url,comptrol)\n",
    "        if skip:\n",
    "            pass\n",
    "        else:\n",
    "            if driver.find_element_by_tag_name('h1').text.lower() == 'page not found':\n",
    "                pass\n",
    "            else:                \n",
    "                clickety_click(driver,url,pre)\n",
    "                lse = pd.concat([lse] + get_data(driver,pre,stonk), axis = 1)\n",
    "    \n",
    "    # This else block deals with the case when comptrol is not zero. I.E. whenI need to start with\n",
    "    # another webdriver.\n",
    "    else:\n",
    "        # In this case I just quit the driver and start another one...\n",
    "        driver.quit()\n",
    "        driver = start_driver(comptrol)\n",
    "        # ...then the rest of the programme is the same as before.\n",
    "        skip = False\n",
    "        pre = len(driver.requests)\n",
    "        try_url(driver,url,comptrol)\n",
    "        if skip:\n",
    "            pass\n",
    "        else:\n",
    "            if driver.find_element_by_tag_name('h1').text.lower() == 'page not found':\n",
    "                pass\n",
    "            else:                \n",
    "                clickety_click(driver,url,pre)\n",
    "                lse = pd.concat([lse] + get_data(driver,pre,stonk), axis = 1)\n",
    "# Finally I quit the driver.\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
